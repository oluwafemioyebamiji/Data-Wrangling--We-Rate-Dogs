{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: Wrangle Report\n",
    "By: Oluwafemi Oyebamiji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project has gathered real world data from a twitter handle \"We rate Dogs\" - @dog_rates. WeRateDogs is a twitter handle that allows people to rate their dog with several interesting comments about each dogs. This data was then extracted to form a datasets including the rating numerators, denominators, etc.\n",
    "\n",
    "<img src='dog-rates-social.jpg'>\n",
    "image source: Udacity\n",
    "\n",
    "## Wrangling Process\n",
    "In ensuring the readiness of the data for analysis, we had taken some data wrangling steps:\n",
    "\n",
    "### 1. Data Gathering:\n",
    "We gathered data from 3 data sources: \n",
    " - the first datasets - twitter_archive_enhanced was supplied by Udacity. According to Udacity, the archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017.\n",
    " - the second datasets - image_predictions.tsv was downloaded using the request library from Use the Requests library from https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv. The second datasets is a resulting file from a neural network prediction about the tweets\n",
    " - the third datasets is downloaded directly from twitter via the twitter API. Note that this requires a developer account, the necessary key and the necessary library to get the data off twitter. This datasets bacially contains favorite_count and retweet_recount for all tweet_id in the first dataset.\n",
    " \n",
    " ### 2. Assessing the Data\n",
    " The focus of this project is to demonstrate enough knowledge of data wrangling, as such, not all quality issues were identified. However, the project investigated at least 8 quality issues and 2 tidiness issues. Both visual assessment and programmatic assessment was employed in identifying the issues with the datasets. The issues identified include:\n",
    " \n",
    " #### Quality issues\n",
    "\n",
    "1. Some columns have wrong datatypes:timestamp: object instead of datetime and IDs (tweet_id\tin_reply_to_status_id\tin_reply_to_user_id) should be object data type.\n",
    "\n",
    "2. The link and the content in source column are embedded with an html <a></a> tag\n",
    "\n",
    "\n",
    "3. In Image Prediction datasets, the algorithm used in Prediction 1 (p1) has the best confidence (59%) compared to the next best algorithm (15%), we should drop other prediction columns to keep only the best prediction (p1, p1_conf and p1 dog).\n",
    "\n",
    "\n",
    "4. There are lots of rows in the expanded url column having two values for a single row e.g. row 6, 7, etc. \n",
    "  - row 6: https://gofundme.com/ydvmve-surgery-for-jax,https://twitter.com/dog_rates/status/890971913173991426/photo/1         \n",
    "  - row 7: https://twitter.com/dog_rates/status/890729181411237888/photo/1,https://twitter.com/dog_rates/status/890729181411237888/photo/1\n",
    "  \n",
    "  \n",
    "5. p1 dog breed column has an high tendency for differences in the capitalisation of the texts resulting in duplicates. All names should be in a similar case such as lower case\n",
    "\n",
    "\n",
    "6. Since this is a social media account, all tweets will definitely not be about dogs. We will trust our P1 prediction as the best alternative and the records predicted not to be dogs are likely not dogs; Drop the P1_dog column.\n",
    "\n",
    "\n",
    "7. Since the universal denominator stipulated is 10 and only 21 rows have denominators higher than 10, while other 2333 has denominators of 10, we should as well normalise all denominators to 10 and drop the denominator column. The numerator column will then be \"rating_over_10\".\n",
    "\n",
    "\n",
    "8. 59 missing data in the expanded url column should be filled. The pattern for other values would be useful.\n",
    "\n",
    "\n",
    "#### Tidiness issues\n",
    "1. The three datasets needs to be combined to form a single datasets since twitter archive is the original dataset and tweet.json (extracted from twitter via API) and Image Predictions File are just additional information gathered on the original dataset \n",
    "2. Dog stages (doggo\tfloofer\tpupper\tpuppo) should form a single column (Dataframe: twitter_archive_enhanced). And there are dogs belonging to more than one stage\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "The Define-Code-Test Framework was employed in cleaning all issues identified and this is documented in the notebook file attached.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
